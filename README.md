# NLPforTS
При написании кода мы опирались на несколько источников

LDA: https://towardsdatascience.com/end-to-end-topic-modeling-in-python-latent-dirichlet-allocation-lda-35ce4ed6b3e0; 
https://melaniewalsh.github.io/Intro-Cultural-Analytics/05-Text-Analysis/11-Topic-Modeling-Time-Series.html;
https://www.kaggle.com/code/sudalairajkumar/getting-started-with-text-preprocessing

BERTopic: https://github.com/MaartenGr/BERTopic/blob/master/notebooks/BERTopic.ipynb

ITMTF: https://github.com/srashee2/CourseProject/tree/main
